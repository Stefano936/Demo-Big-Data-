# Demo Big Data - Cadena de Cines

Pipeline ETL para procesar datos de pelÃ­culas de IMDb en un Data Lake con arquitectura de capas (Landing â†’ Raw â†’ Curated).


## ğŸš€ InstalaciÃ³n

### 1. Clonar el repositorio

```bash
git clone https://github.com/Stefano936/Demo-Big-Data-.git
cd Demo-Big-Data-/proyecto_cadena_cines
```

## ğŸ“ Estructura de directorios

El pipeline requiere la siguiente estructura de carpetas:

```
proyecto_cadena_cines/
â”œâ”€â”€ pipeline.py                 # Script principal
â”œâ”€â”€ data_original/              # ğŸ“¥ Archivos fuente (REQUIERE AGREGAR)
â”‚   â”œâ”€â”€ title.basics.tsv       # Datos bÃ¡sicos de tÃ­tulos IMDb
â”‚   â””â”€â”€ title.ratings.tsv      # Ratings e informaciÃ³n de votos
â””â”€â”€ analytics/                 # âš ï¸ KPIs y grÃ¡ficas (se genera automÃ¡ticamente)
```

**NOTA:** Las carpetas marcadas con âš ï¸ se crean automÃ¡ticamente al ejecutar el pipeline.

## ğŸ“¥ Descargar archivos de IMDb

Los archivos TSV no estÃ¡n en el repositorio por su tamaÃ±o. Debes descargarlos manualmente de IMDb:

### OpciÃ³n 1: Descarga manual

1. Visita: https://datasets.imdbws.com/
2. Descarga los siguientes archivos:
   - `title.basics.tsv.gz`
   - `title.ratings.tsv.gz`
3. Descomprimelos y renÃ³mbralos quitando la extensiÃ³n `.gz`
4. Copia ambos archivos a la carpeta `data_original/`

### OpciÃ³n 2: Script de descarga (si tienes wget o curl)

```powershell
# En Windows PowerShell, desde la carpeta proyecto_cadena_cines:
$url_basics = "https://datasets.imdbws.com/title.basics.tsv.gz"
$url_ratings = "https://datasets.imdbws.com/title.ratings.tsv.gz"

# Crear carpeta si no existe
New-Item -ItemType Directory -Path "data_original" -Force

# Descargar
Invoke-WebRequest -Uri $url_basics -OutFile "data_original/title.basics.tsv.gz"
Invoke-WebRequest -Uri $url_ratings -OutFile "data_original/title.ratings.tsv.gz"

# Descomprimir (necesita 7-Zip o similar instalado)
```

## ğŸ‹ Levantar el docker

```bash
cd proyecto_cadena_cines
docker compose up --build
```

## â–¶ï¸ Ejecutar el pipeline

Una vez que hayas agregado los archivos TSV en `data_original/`:

```bash
bash pipeline_spark.sh
```

## ğŸ“Š Â¿QuÃ© hace el pipeline?

El pipeline ejecuta 4 etapas automÃ¡ticamente:

### 1ï¸âƒ£ **Ingesta (Landing)**
- Copia `title.basics.tsv` y `title.ratings.tsv` desde `data_original/` a `datalake/landing/`

### 2ï¸âƒ£ **Procesamiento (Raw)**
- Lee archivos TSV
- Normaliza nombres de columnas a minÃºsculas
- Guarda como CSV en `datalake/raw/`
  - `basics_raw.csv`
  - `ratings_raw.csv`

### 3ï¸âƒ£ **IntegraciÃ³n (Curated)**
- Filtra solo pelÃ­culas (excluye series, documentales, etc.)
- Une datos de bÃ¡sicos + ratings
- Elimina filas con valores faltantes crÃ­ticos
- Genera columna `genre_principal`
- Guarda en `datalake/curated/movies_curated.csv`

### 4ï¸âƒ£ **Analytics (KPIs)**
Genera 3 reportes en `analytics/`:
- `ratings_por_genero.csv` â†’ Rating promedio por gÃ©nero
- `popularidad_por_anio.csv` â†’ Votos promedio por aÃ±o de estreno
- `distribucion_duracion.csv` â†’ EstadÃ­sticas de duraciÃ³n de pelÃ­culas

## ğŸ Publicar curated a HIVE

Una vez terminado el pipeline, se toman los datos de curated y se pasan a HIVE con:
```bash
bash load_curated_to_hive.sh
```

## ğŸ” SoluciÃ³n de problemas

### âŒ Error: "No se encontrÃ³ data_original/title.basics.tsv"
**SoluciÃ³n:** Verifica que los archivos TSV estÃ©n en la carpeta `data_original/` correctamente nombrados.

### âŒ Error: "No existe movies_curated.csv"
**SoluciÃ³n:** AsegÃºrate de que el pipeline se ejecutÃ³ correctamente sin errores en etapas anteriores.

### âŒ Error de memoria con archivos muy grandes
**SoluciÃ³n:** El archivo `title.basics.tsv` (~1 GB) requiere al menos 4 GB de RAM disponible.

## ğŸ“ Archivos del proyecto

| Archivo | DescripciÃ³n |
|---------|-------------|
| `analytics/GrÃ¡ficas.pbix` | GrÃ¡ficas y resultados |
| `load_curated_to_hive.sh` | Cargado de datos a servidor de HIVE |
| `pipeline_spark.py` | IngestiÃ³n de datos y pipeline |
| `pipeline_spark.py` | Script principal del ETL ejecutado en el medio del .sh |
| `pipeline.py` | Script viejo principal del ETL |
| `docker-compose.yml` | ImÃ¡gen usada por el repositorio |
| `hadoop-hive.env` | ConfiguraciÃ³n de HIVE |
| `hadoop.env` | ConfiguraciÃ³n de hadoop |
| `README.md` | Este archivo |
| `.gitignore` | ConfiguraciÃ³n para excluir archivos grandes |

## ğŸ”— Referencias

- IMDb Datasets: https://datasets.imdbws.com/
- DocumentaciÃ³n de pandas: https://pandas.pydata.org/

## ğŸ“§ Notas

- Los archivos `.tsv` originales NO estÃ¡n en el repositorio (excedÃ­an lÃ­mite de GitHub)
- Se requiere descargarlos manualmente desde IMDb
- El pipeline estÃ¡ optimizado para arquitectura de Data Lake moderna
